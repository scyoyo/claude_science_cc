"""
Exporter: Export meeting artifacts in various formats.

Supports:
- ZIP download: Bundle all code artifacts into a zip file
- GitHub push preparation: Generate file structure for GitHub
- Google Colab notebook: Convert code artifacts to .ipynb format
"""

import io
import json
import zipfile
from typing import List

from app.schemas.artifact import CodeArtifactResponse


def export_as_zip(
    artifacts: List[dict],
    project_name: str = "virtual_lab_export",
) -> bytes:
    """Export artifacts as a ZIP file.

    Args:
        artifacts: List of artifact dicts with 'filename', 'content', 'language' keys.
        project_name: Name of the root directory in the zip.

    Returns:
        Bytes of the ZIP file.
    """
    buffer = io.BytesIO()
    with zipfile.ZipFile(buffer, "w", zipfile.ZIP_DEFLATED) as zf:
        # Add a README
        readme = f"# {project_name}\n\nGenerated by Virtual Lab\n\n## Files\n\n"
        for a in artifacts:
            readme += f"- `{a['filename']}` ({a['language']})\n"
        zf.writestr(f"{project_name}/README.md", readme)

        # Add each artifact
        for a in artifacts:
            zf.writestr(f"{project_name}/{a['filename']}", a["content"])

    return buffer.getvalue()


def export_as_colab_notebook(
    artifacts: List[dict],
    project_name: str = "virtual_lab_export",
) -> dict:
    """Export artifacts as a Google Colab-compatible Jupyter notebook.

    Args:
        artifacts: List of artifact dicts.
        project_name: Name for the notebook title.

    Returns:
        Dict representing the .ipynb JSON structure.
    """
    cells = []

    # Title cell
    cells.append({
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            f"# {project_name}\n",
            "\n",
            "Generated by Virtual Lab\n",
        ],
    })

    # One cell per artifact
    for a in artifacts:
        # Description markdown cell
        desc = a.get("description", "")
        cells.append({
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                f"## {a['filename']}\n",
                f"\n{desc}\n" if desc else "",
            ],
        })

        # Code cell
        cell_type = "code" if a["language"] in ("python", "py") else "code"
        source_lines = a["content"].split("\n")
        source_with_newlines = [line + "\n" for line in source_lines[:-1]]
        if source_lines:
            source_with_newlines.append(source_lines[-1])

        cells.append({
            "cell_type": cell_type,
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": source_with_newlines,
        })

    notebook = {
        "nbformat": 4,
        "nbformat_minor": 0,
        "metadata": {
            "colab": {"name": f"{project_name}.ipynb"},
            "kernelspec": {
                "name": "python3",
                "display_name": "Python 3",
            },
            "language_info": {"name": "python"},
        },
        "cells": cells,
    }

    return notebook


def export_as_github_files(
    artifacts: List[dict],
    project_name: str = "virtual_lab_export",
) -> List[dict]:
    """Prepare artifacts as a list of files for GitHub push.

    Args:
        artifacts: List of artifact dicts.
        project_name: Repository/project name.

    Returns:
        List of dicts with 'path' and 'content' keys ready for GitHub API.
    """
    files = []

    # README
    readme = f"# {project_name}\n\nGenerated by Virtual Lab\n\n## Files\n\n"
    for a in artifacts:
        readme += f"- `{a['filename']}` ({a['language']})\n"
    files.append({"path": "README.md", "content": readme})

    # Artifacts
    for a in artifacts:
        files.append({"path": a["filename"], "content": a["content"]})

    return files
